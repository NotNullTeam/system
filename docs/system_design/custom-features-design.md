# 定制化功能设计方案
> 相较于复现烂大街的RAG的解决方案，侧重实现运维定制化功能才是比赛的重点。本文档详细阐述了如何实现竞赛要求中的各项高度定制化与创新性功能。

### 1. 两阶段检索：召回 (Recall) + 精排 (Rerank)

-   **核心思路**: 传统的单阶段向量检索（或混合检索）在处理复杂问题时可能召回许多相关性不高的“噪音”文档。我们采用“召回+精排”的两阶段范式，来确保最终提交给LLM的上下文质量最高。
-   **第一阶段 (召回)**:
    -   **目标**: 尽可能多地召回所有可能相关的文档，宁可错杀三千，不可放过一个。
    -   **实现**: 并行执行两种召回策略，并将结果合并去重：
        1.  **关键词召回 (BM25)**: 利用 Weaviate 内置的BM25算法，进行传统的关键词匹配。对包含大量专业术语的运维场景非常有效。
        2.  **向量召回**: 使用阿里云百炼平台的 `text-embedding-v4` 模型，将用户问题向量化后在 Weaviate 中进行向量相似度检索。
-   **第二阶段 (精排)**:
    -   **目标**: 对第一阶段召回的候选文档列表（例如 Top 50）进行更精细、更昂贵的计算，得到最准确的相关性排序。
    -   **实现**: 通过Langchain集成调用OLLAMA本地部署的 `Qwen3-Reranker` 重排序模型。使用统一的Langchain接口，接收用户问题和每一篇候选文档，输出精确的相关性分数。
    -   **最终上下文**: 选取重排后分数最高的 Top-K (例如 Top 5) 文档，作为最终的知识上下文。

### 2. 先进的文档处理 (IDP & 语义切分)

-   **核心思路**: 垃圾进，垃圾出。高质量的知识库是RAG系统的基石。

**实现策略**：构建一个基于“解析-理解-重构”的三阶段文档处理流水线。

### 第一阶段：细粒度混合解析

-   **问题**：传统的电子文本提取无法处理扫描版PDF或图片，而通用OCR又难以精准识别复杂的表格和公式。
-   **解决方案**：采用**阿里云文档智能（Document Mind）** 等IDP服务。它能智能判断文档类型，并融合多种技术进行解析：
    -   **电子解析**：针对数字原生PDF，快速提取文本和元数据。
    -   **OCR/NLP**：针对扫描件或图片，利用视觉和自然语言处理技术，精准识别文本、表格、印章等内容。
    -   通过优势互补，极大提升了对混合型文档（如部分扫描、部分电子的PDF）的解析准确率和覆盖度。

### 第二阶段：基于版面分析的语义切分

-   **问题**：按固定长度或分隔符切分文本（如`RecursiveCharacterTextSplitter`），极易切断完整的语义单元（如一个表格及其标题、一个代码块、一个列表项）。
-   **解决方案**：利用基于**GeoLayoutLM**等先进模型构建的**层级树分析能力**。
    -   该技术不再将文档视为线性文本流，而是解析其**二维版面布局**，构建一个包含标题、段落、列表、表格、图片等元素的**文档结构树**。
    -   我们基于这棵树进行“语义切分”，确保每个切片（Chunk）都是一个逻辑上完整、独立的单元。例如，一张完整的表格连同其说明文字会被切分在一起。这保证了输入到RAG下游链路的知识片段语义不丢失。

### 第三阶段：生成LLM友好的结构化Markdown

-   **问题**：普通文本块（Plain Text）缺少结构信息，LLM难以理解其上下文重要性（例如，一段文字是正文还是脚注？）。
-   **解决方案**：将解析和切分后的内容，重构为一种**携带丰富元数据的结构化Markdown**。
    -   **输出格式**：除了文本内容，输出的Markdown/JSON中还将包含：
        -   `层级信息`：明确的标题层级（H1, H2, ...）。
        -   `元素类型`：显式标注普通段落、表格、图片、代码块等。
        -   `位置信息`：每个元素在原始文档中的页码、坐标等。
    -   这种LLM友好的格式，使模型在处理时能更好地理解上下文，从而生成更精准、更忠于原文的答案。

**关联工作流**：
*   该IDP流程是**知识处理流水线**（由后端服务的后台任务触发）的核心组成部分，是所有文档入库前的必经步骤，取代了传统的`pdfplumber`或`BeautifulSoup`等单一解析库。

## 3. 知识自进化（带反馈的闭环系统）

**目标**：建立一个用户反馈机制，允许将经过验证的、高质量的问答对或解决方案沉淀回知识库，使系统能够持续学习和成长。

**实现策略**：

1.  **前端反馈界面**：在每个生成的答案旁边，提供明确的反馈按钮，如“👍 满意”、“👎 不满意”，以及一个“编辑并提交正确答案”的文本框。

2.  **后端反馈API**：创建一个API端点（`POST /cases/{caseId}/feedback`），用于接收前端提交的反馈数据。数据应包含：原始问题、模型生成的答案、用户评分、用户修正后的答案（如果有）以及相关的会话ID。

3.  **反馈数据暂存**：将收集到的反馈信息存储在后端数据库（SQLite）的一个专门的 `feedback` 表中，并标记状态为“待审核”。

4.  **人工审核与标注**：定期对“待审核”的反馈进行人工审查。对于有价值的反馈（例如一个被用户验证为正确的、全新的解决方案），审核员将其改写、标注为一篇高质量的知识文档（例如Markdown格式）。

5.  **知识入库自动化**：
    *   将审核通过的知识文档保存到用于存放“已验证知识”的**本地文件夹**中。
    *   通过**文件系统事件监听或后台轮询**，自动触发知识处理流水线：新文档出现 → 自动切片 → 调用text-embedding-v4模型进行向量化 → 存入本地的 **Weaviate** 向量数据库。
    *   至此，新的知识就可被未来的用户查询所检索到，完成整个闭环。

**关联API**：
*   **`POST /cases/{caseId}/feedback`**: 用户通过此接口提交对整个诊断案例的最终反馈，包括评价（`solved` / `unsolved`）和修正后的解决方案。这是知识自进化流程的起点。

<br>

## 4. 大模型Agent能力（主动提问与多轮对话）

**目标**：当用户输入的问题信息不足或模糊时，系统能像专家一样主动发起追问，引导用户提供关键信息，最终完成任务。

**实现策略**：利用 `langgraph` 构建一个基于状态机的多轮对话智能体（Agent）。

### 3. `langgraph` Agent 实现多轮交互与工具调用

-   **核心思路**: 将诊断流程建模为一个状态图 (State Graph)，其中每个节点是一个操作(例如，调用LLM，调用工具)，每条边是一个判断逻辑。
-   **状态 (State)**: 包含 `messages` (对话历史), `context` (检索到的知识), `caseId` 等。
-   **节点 (Nodes)**:
    -   `call_model`: 调用阿里云百炼平台的LLM API (`qwen3-plus`)，根据当前状态生成下一步的分析或问题。
    -   `retrieve_knowledge`: 调用混合检索模块，更新状态中的`context`。
    -   `generate_tool_code`: 当LLM决定需要执行工具(如`ping`, `traceroute`)时，生成相应的可执行代码。
-   **边 (Edges)**:
    -   根据LLM的输出，决定下一跳是再次检索，还是向用户提问，还是给出解决方案。
    -   例如，如果LLM的输出包含特定标记 `<TOOL_CALL>`，则路由到 `generate_tool_code` 节点。

**关联API**：
*   **`POST /cases`**: 当用户发起第一次提问时，调用此接口创建新的诊断案例（Case）和初始的对话图（包含用户问题节点和AI的首次分析节点）。
*   **`POST /cases/{caseId}/interactions`**: 在后续的每一轮交互中，用户通过此接口提交补充信息。后端Agent根据新信息驱动状态机，返回新增的节点（可能是AI的进一步追问，也可能是最终解决方案）。
*   **`GET /cases/{caseId}`**: 用于获取整个案例的完整对话历史和图谱结构。

<br>

## 5. 跨厂商解决方案生成

**目标**：系统能识别问题的上下文涉及哪家网络设备厂商（如华为、思科），并生成符合该厂商命令行语法的解决方案。

**实现策略**：

1.  **知识库预处理**：在构建知识库时，为所有文档片段（Chunks）打上元数据（Metadata）标签。例如，从华为手册中提取的知识，其元数据应包含 `{"vendor": "huawei"}`；思科的则为 `{"vendor": "cisco"}`。

2.  **厂商意图识别**：
    *   **Agent追问**：在上一节的Agent流程中，如果上下文中没有厂商信息，可以增加一个追问：“请问您操作的设备是华为、思科还是其他厂商？”
    *   **关键词推断**：通过问题中出现的关键词（如`display` vs `show`，`VRP` vs `IOS`）来初步推断厂商。

3.  **元数据过滤检索**：在执行RAG检索时，使用已识别出的厂商信息对向量数据库进行**元数据过滤**。例如，如果识别出是华为，则只在 `{"vendor": "huawei"}` 的文档片段中进行搜索。`LangChain`的检索器完美支持此功能。

4.  **上下文指令注入（Prompt Engineering）**：在最后调用大模型生成答案的Prompt中，明确注入厂商指令。例如：
    > “你是一位资深的华为网络专家。请严格根据以下上下文信息，使用华为VRP系统的命令语法，为用户提供解决方案：[...检索到的华为文档...]”

**关联API**：
*   **`POST /cases/{caseId}/interactions`**: 在调用此接口时，可以在请求体中通过 `filterTags` 参数传入明确的厂商标识（如 `["Huawei"]`），从而在后端进行精确的元数据过滤检索。
*   **`GET /cases/{caseId}/nodes/{nodeId}/commands`**: 如果返回的解决方案节点（Node）中包含了具体操作命令，可以通过此接口获取与该节点关联的、按厂商分类的命令列表。

<br>

## 6. 结果可解释性（高亮引用来源）

**目标**：在生成的答案中，明确标注出每一句话或关键信息来源于哪篇原始文档的哪个部分，增加答案的可信度和可追溯性。

**实现策略**：

1.  **检索时返回元数据**：确保RAG检索器在返回文档片段内容的同时，也返回其完整的元数据，至少包含：`source_document_name`（源文件名）、`page_number`（页码）、`chunk_id`（片段ID）。

2.  **强制模型引用**：使用 `LangChain` 提供的 `create_citation_chain` 或类似技术。在调用大模型生成答案的Prompt中，强制要求模型在生成内容时，必须在引用了上下文信息的地方，带上如 `[doc1]`、`[doc2]` 这样的引用标记。

3.  **结构化API响应**：改造后端API的返回格式。不要只返回一个字符串，而应返回一个JSON对象，包含两部分：
    ```json
    {
      "answer": "为解决OSPF邻居ExStart状态问题，您需要检查接口的MTU值 [doc1]。在华为设备上，可以使用命令 `display ip interface brief` 来查看 [doc2]。",
      "sources": [
        { "id": "doc1", "file": "HUAWEI-OSPF故障排查手册.pdf", "page": 25 },
        { "id": "doc2", "file": "华为VRP命令参考.pdf", "page": 112 }
      ]
    }
    ```

4.  **前端高亮展示**：前端应用解析这个JSON。在显示 `answer` 文本时，将 `[doc1]` 等引用标记渲染成可点击的标签。当用户鼠标悬浮或点击该标签时，弹出一个卡片，显示 `sources` 数组中对应ID的来源信息（文件名和页码），甚至可以链接到原文。 

**关联API**：
*   **`GET /cases/{caseId}/nodes/{nodeId}`**: 当用户点击某个解决方案节点查看详情时，调用此接口。其返回的 `Node` 对象的 `content` 字段中，就包含了带有引用标记的 `answer` 文本和 `sources` 数组，前端可直接用于渲染。
*   **`GET /cases/{caseId}/nodes/{nodeId}/knowledge`**: 除了在答案中高亮，系统还可以提供一个专门的“知识溯源”功能。调用此接口可以获取生成该节点（Node）时所引用的所有知识库文档片段及其相似度分数，提供更深层次的可解释性。 