#!/usr/bin/env python3
"""
LangGraph Agent ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•

æµ‹è¯•å®Œæ•´çš„ langgraph Agent å·¥ä½œæµï¼ŒåŒ…æ‹¬ä»»åŠ¡æäº¤ã€çŠ¶æ€ç›‘æ§å’Œç»“æœéªŒè¯ã€‚
"""

import sys
import os
import time
import logging
import pytest
from unittest.mock import patch, Mock

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„ï¼ˆç”¨äºç‹¬ç«‹è¿è¡Œï¼‰
if __name__ == "__main__":
    sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from app import create_app, db
from app.models.case import Case, Node
from app.services.ai.langgraph_agent_service import (
    submit_langgraph_query_analysis_task,
    get_langgraph_task_status
)

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


@pytest.mark.integration
@pytest.mark.langgraph
class TestLanggraphEndToEnd:
    """LangGraph Agent ç«¯åˆ°ç«¯æµ‹è¯•"""

    def test_agent_state_and_nodes(self, app):
        """æµ‹è¯•AgentçŠ¶æ€å’ŒèŠ‚ç‚¹å®šä¹‰"""
        with app.app_context():
            try:
                from app.services.ai.agent_state import AgentState
                from app.services.ai.agent_nodes import analyze_query, retrieve_knowledge, generate_solution
                from app.services.ai.agent_workflow import create_agent_workflow

                logger.info("æµ‹è¯•AgentçŠ¶æ€å®šä¹‰...")
                test_state: AgentState = {
                    "messages": [],
                    "context": [],
                    "user_query": "æµ‹è¯•æŸ¥è¯¢",
                    "vendor": "Huawei",
                    "category": None,
                    "need_more_info": False,
                    "solution_ready": False,
                    "case_id": "test_case",
                    "current_node_id": "test_node",
                    "analysis_result": None,
                    "clarification": None,
                    "solution": None,
                    "error": None,
                    "step": "initializing"
                }

                # éªŒè¯çŠ¶æ€å­—æ®µ
                assert test_state["user_query"] == "æµ‹è¯•æŸ¥è¯¢"
                assert test_state["vendor"] == "Huawei"
                assert test_state["step"] == "initializing"
                assert test_state["need_more_info"] is False
                assert test_state["solution_ready"] is False

                logger.info("âœ… AgentçŠ¶æ€å®šä¹‰æ­£å¸¸")

                logger.info("æµ‹è¯•Agentå·¥ä½œæµåˆ›å»º...")
                workflow = create_agent_workflow()
                assert workflow is not None
                logger.info("âœ… Agentå·¥ä½œæµåˆ›å»ºæˆåŠŸ")

            except Exception as e:
                logger.error(f"Agentç»„ä»¶æµ‹è¯•å¤±è´¥: {str(e)}")
                pytest.fail(f"Agentç»„ä»¶æµ‹è¯•å¤±è´¥: {str(e)}")

    @pytest.mark.slow
    @patch('app.services.ai.langgraph_agent_service.get_task_queue')
    def test_langgraph_workflow_integration(self, mock_get_task_queue, app, sample_user):
        """æµ‹è¯•langgraphå·¥ä½œæµé›†æˆï¼ˆæ¨¡æ‹Ÿç‰ˆæœ¬ï¼‰"""
        with app.app_context():
            try:
                # æ¨¡æ‹Ÿé˜Ÿåˆ—å’Œä»»åŠ¡
                mock_queue = Mock()
                mock_get_task_queue.return_value = mock_queue

                mock_job = Mock()
                mock_job.id = "test_job_123"
                mock_queue.enqueue.return_value = mock_job

                # åˆ›å»ºæµ‹è¯•æ¡ˆä¾‹
                logger.info("åˆ›å»ºæµ‹è¯•æ¡ˆä¾‹...")
                case = Case(
                    title="æµ‹è¯•langgraph Agent",
                    user_id=sample_user.id,
                    metadata={
                        'vendor': 'Huawei',
                        'use_langgraph': True,
                        'original_query': 'OSPFé‚»å±…å»ºç«‹å¤±è´¥ï¼Œè¯·å¸®å¿™åˆ†æåŸå› ',
                        'created_with_langgraph': True
                    }
                )
                db.session.add(case)
                db.session.flush()

                # åˆ›å»ºæµ‹è¯•èŠ‚ç‚¹
                node = Node(
                    case_id=case.id,
                    type='AI_ANALYSIS',
                    title='AIåˆ†æä¸­...',
                    status='PROCESSING',
                    node_metadata={
                        'timestamp': time.time()
                    }
                )
                db.session.add(node)
                db.session.flush()
                db.session.commit()

                logger.info(f"æµ‹è¯•æ¡ˆä¾‹åˆ›å»ºæˆåŠŸ: case_id={case.id}, node_id={node.id}")

                # æäº¤langgraphä»»åŠ¡
                logger.info("æäº¤langgraphåˆ†æä»»åŠ¡...")
                test_query = "OSPFé‚»å±…å»ºç«‹å¤±è´¥ï¼Œæ—¥å¿—æ˜¾ç¤ºHelloåŒ…æ²¡æœ‰æ”¶åˆ°å›å¤ï¼Œç½‘ç»œç¯å¢ƒæ˜¯ä¸‰å±‚äº¤æ¢æœºç»„ç½‘"

                job_id = submit_langgraph_query_analysis_task(
                    case_id=str(case.id),
                    node_id=str(node.id),
                    query=test_query
                )

                logger.info(f"ä»»åŠ¡æäº¤æˆåŠŸ: job_id={job_id}")

                # éªŒè¯ä»»åŠ¡æäº¤
                assert job_id == "test_job_123"
                mock_queue.enqueue.assert_called_once()

                logger.info("âœ… langgraphå·¥ä½œæµé›†æˆæµ‹è¯•æˆåŠŸ!")

            except Exception as e:
                logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
                pytest.fail(f"langgraphå·¥ä½œæµæµ‹è¯•å¤±è´¥: {str(e)}")


# å¦‚æœéœ€è¦çœŸå®çš„ç«¯åˆ°ç«¯æµ‹è¯•ï¼ˆéœ€è¦å®é™…çš„Rediså’Œæ•°æ®åº“ï¼‰
@pytest.mark.slow
@pytest.mark.e2e
@pytest.mark.skipif(
    True,  # é»˜è®¤è·³è¿‡ï¼Œé™¤éæ˜ç¡®éœ€è¦è¿è¡ŒçœŸå®é›†æˆæµ‹è¯•
    reason="éœ€è¦çœŸå®çš„Rediså’Œå®Œæ•´ç¯å¢ƒæ”¯æŒï¼Œä»…åœ¨å®Œæ•´é›†æˆæµ‹è¯•æ—¶è¿è¡Œ"
)
class TestLanggraphRealIntegration:
    """çœŸå®ç¯å¢ƒä¸‹çš„ LangGraph é›†æˆæµ‹è¯•"""

    def test_real_langgraph_workflow(self, app, sample_user):
        """æµ‹è¯•çœŸå®çš„langgraphå·¥ä½œæµï¼ˆéœ€è¦å®Œæ•´ç¯å¢ƒï¼‰"""
        with app.app_context():
            try:
                # åˆ›å»ºæµ‹è¯•æ¡ˆä¾‹
                logger.info("åˆ›å»ºæµ‹è¯•æ¡ˆä¾‹...")
                case = Case(
                    title="æµ‹è¯•langgraph Agent - çœŸå®ç¯å¢ƒ",
                    user_id=sample_user.id,
                    metadata={
                        'vendor': 'Huawei',
                        'use_langgraph': True,
                        'original_query': 'OSPFé‚»å±…å»ºç«‹å¤±è´¥ï¼Œè¯·å¸®å¿™åˆ†æåŸå› ',
                        'created_with_langgraph': True
                    }
                )
                db.session.add(case)
                db.session.flush()

                # åˆ›å»ºæµ‹è¯•èŠ‚ç‚¹
                node = Node(
                    case_id=case.id,
                    type='AI_ANALYSIS',
                    title='AIåˆ†æä¸­...',
                    status='PROCESSING',
                    node_metadata={
                        'timestamp': time.time()
                    }
                )
                db.session.add(node)
                db.session.flush()
                db.session.commit()

                logger.info(f"æµ‹è¯•æ¡ˆä¾‹åˆ›å»ºæˆåŠŸ: case_id={case.id}, node_id={node.id}")

                # æäº¤langgraphä»»åŠ¡
                logger.info("æäº¤langgraphåˆ†æä»»åŠ¡...")
                test_query = "OSPFé‚»å±…å»ºç«‹å¤±è´¥ï¼Œæ—¥å¿—æ˜¾ç¤ºHelloåŒ…æ²¡æœ‰æ”¶åˆ°å›å¤ï¼Œç½‘ç»œç¯å¢ƒæ˜¯ä¸‰å±‚äº¤æ¢æœºç»„ç½‘"

                job_id = submit_langgraph_query_analysis_task(
                    case_id=str(case.id),
                    node_id=str(node.id),
                    query=test_query
                )

                logger.info(f"ä»»åŠ¡æäº¤æˆåŠŸ: job_id={job_id}")

                # ç›‘æ§ä»»åŠ¡çŠ¶æ€
                logger.info("ç›‘æ§ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€...")
                max_wait_time = 120  # æœ€å¤§ç­‰å¾…2åˆ†é’Ÿ
                start_time = time.time()

                while time.time() - start_time < max_wait_time:
                    status = get_langgraph_task_status(job_id)

                    logger.info(f"ä»»åŠ¡çŠ¶æ€: {status.get('status')}, è¿›åº¦: {status.get('progress', 0)}%, æ­¥éª¤: {status.get('step', 'unknown')}")

                    if status.get('status') in ['completed', 'failed']:
                        break

                    time.sleep(5)  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡

                # è·å–æœ€ç»ˆçŠ¶æ€
                final_status = get_langgraph_task_status(job_id)
                logger.info(f"æœ€ç»ˆä»»åŠ¡çŠ¶æ€: {final_status}")

                # æ£€æŸ¥èŠ‚ç‚¹æ›´æ–°ç»“æœ
                db.session.refresh(node)
                logger.info(f"èŠ‚ç‚¹æœ€ç»ˆçŠ¶æ€: type={node.type}, status={node.status}")
                logger.info(f"èŠ‚ç‚¹å†…å®¹: {node.content}")

                if final_status.get('status') == 'completed':
                    logger.info("âœ… langgraphå·¥ä½œæµæµ‹è¯•æˆåŠŸ!")
                    assert True
                else:
                    logger.error("âŒ langgraphå·¥ä½œæµæµ‹è¯•å¤±è´¥!")
                    pytest.fail("langgraphå·¥ä½œæµæœªèƒ½æˆåŠŸå®Œæˆ")

            except Exception as e:
                logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
                pytest.fail(f"çœŸå®é›†æˆæµ‹è¯•å¤±è´¥: {str(e)}")


# ä¾¿æ·çš„å•ç‹¬è¿è¡Œå‡½æ•°ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
def main():
    """ä¸»å‡½æ•° - ç”¨äºç‹¬ç«‹è¿è¡Œæµ‹è¯•"""
    logger.info("å¼€å§‹æµ‹è¯•langgraph Agentå®ç°...")

    app = create_app()

    # æµ‹è¯•åŸºç¡€ç»„ä»¶
    test_class = TestLanggraphEndToEnd()

    try:
        test_class.test_agent_state_and_nodes(app)
        logger.info("âœ… åŸºç¡€ç»„ä»¶æµ‹è¯•é€šè¿‡")

        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼langgraph Agentå®ç°æ­£å¸¸")
        assert True  # æµ‹è¯•é€šè¿‡

    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {str(e)}")
        assert False, "æµ‹è¯•å¤±è´¥"


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
